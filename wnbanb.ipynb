{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd00afcdae27aaf7733bf8811b8166f5ce243ed351118e80cd2bacc277dd0792f6e",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "The kernel died. View Jupyter [log](command:jupyter.viewOutput) for further details. \nError: ImportError: DLL load failed while importing error: The specified module could not be found.\r...",
     "traceback": [
      "Error:",
      "at new o (c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:16:22781)",
      "at new i (c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:16:83282)",
      "at b.launch (c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:52:768136)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "Error: Kernel died with exit code 1. Traceback (most recent call last):",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main",
      "return _run_code(code, main_globals, None,",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\runpy.py\", line 87, in _run_code",
      "exec(code, run_globals)",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 15, in <module>",
      "from ipykernel import kernelapp as app",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\ipykernel\\__init__.py\", line 2, in <module>",
      "from .connect import *",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\ipykernel\\connect.py\", line 18, in <module>",
      "import jupyter_client",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\jupyter_client\\__init__.py\", line 4, in <module>",
      "from .connect import *",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\jupyter_client\\connect.py\", line 21, in <module>",
      "import zmq",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\__init__.py\", line 50, in <module>",
      "from zmq import backend",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\backend\\__init__.py\", line 40, in <module>",
      "reraise(*exc_info)",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\utils\\sixcerpt.py\", line 34, in reraise",
      "raise value",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\backend\\__init__.py\", line 27, in <module>",
      "_ns = select_backend(first)",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\backend\\select.py\", line 28, in select_backend",
      "mod = __import__(name, fromlist=public_api)",
      "File \"C:\\Users\\saiem\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\__init__.py\", line 6, in <module>",
      "from . import (constants, error, message, context,",
      "ImportError: DLL load failed while importing error: The specified module could not be found.",
      "at c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:52:764377",
      "at c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:52:430998",
      "at c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:52:431216",
      "at Immediate._onImmediate (c:\\Users\\saiem\\.vscode\\extensions\\ms-toolsai.jupyter-2021.6.811652604\\out\\client\\extension.js:52:432781)",
      "at processImmediate (internal/timers.js:461:21)"
     ]
    }
   ],
   "source": [
    "from numpy.core.fromnumeric import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import http\n",
    "import urllib\n",
    "from urllib.error import URLError, HTTPError, ContentTooShortError\n",
    "from datetime import datetime\n",
    "from itertools import chain, starmap\n",
    "\n",
    "\n",
    "\n",
    "def download(self, url, num_retries=5):\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "    except (URLError, HTTPError, ContentTooShortError, http.client.HTTPException, http.client.IncompleteRead) as e:\n",
    "        print('Download error:', url)\n",
    "        html = None\n",
    "        if num_retries > 0:\n",
    "            if hasattr(e, 'code') and 500 <= e.code < 600:\n",
    "                time.sleep(10)\n",
    "                # recursively retry 5xx HTTP errors\n",
    "                return self.download(url, num_retries - 1)\n",
    "        if num_retries > 0:\n",
    "            if e == http.client.IncompleteRead:\n",
    "                time.sleep(10)\n",
    "                return self.download(url, num_retries - 1)\n",
    "    return html\n",
    "\n",
    "def flatten_json_iterative(self, dictionary, sep = '.', ind_start = 0):\n",
    "    \"\"\"Flattening a nested json file\"\"\"\n",
    "    def unpack_one(parent_key, parent_value):\n",
    "        \"\"\"Unpack one level (only one) of nesting in json file\"\"\"\n",
    "        # Unpacking one level\n",
    "        if isinstance(parent_value, dict):\n",
    "            for key, value in parent_value.items():\n",
    "                t1 = parent_key + sep + key\n",
    "                yield t1, value\n",
    "        elif isinstance(parent_value, list):\n",
    "            i = ind_start \n",
    "            for value in parent_value:\n",
    "                t2 = parent_key + sep +str(i)\n",
    "                i += 1\n",
    "                yield t2, value\n",
    "        else:\n",
    "            yield parent_key, parent_value\n",
    "    # Continue iterating the unpack_one function until the terminating condition is satisfied\n",
    "    while True:\n",
    "        # Continue unpacking the json file until all values are atomic elements (aka neither a dictionary nor a list)\n",
    "        dictionary = dict(chain.from_iterable(starmap(unpack_one, dictionary.items())))\n",
    "        # Terminating condition: none of the values in the json file are a dictionary or a list\n",
    "        if not any(isinstance(value, dict) for value in dictionary.values()) and \\\n",
    "        not any(isinstance(value, list) for value in dictionary.values()):\n",
    "            break\n",
    "    return dictionary\n",
    "\n",
    "def wnba_pbp(self):\n",
    "    \"\"\"\n",
    "        wnba_pbp()\n",
    "        Pull the game by id\n",
    "        Data from API endpoints:\n",
    "            * wnba/playbyplay\n",
    "            * wnba/summary\n",
    "    \"\"\"\n",
    "    # play by play\n",
    "    pbp_url = \"http://cdn.espn.com/wnba/playbyplay?gameId={}&xhr=1&render=false&userab=18\".format(self.gameId)\n",
    "    pbp_resp = self.download(url=pbp_url)\n",
    "    pbp_txt = {}\n",
    "    pbp_txt['standings'] = np.array([])\n",
    "    pbp_txt['videos'] = np.array([])\n",
    "    pbp_txt['broadcasts'] = np.array([])\n",
    "    pbp_txt['winprobability'] = np.array([])\n",
    "    pbp_txt['espnWP'] = np.array([])\n",
    "    pbp_txt['gameInfo'] = {}\n",
    "    pbp_txt['season'] = np.array([])\n",
    "\n",
    "    pbp_txt = json.loads(pbp_resp)['gamepackageJSON']\n",
    "    pbp_txt['odds'] = np.array([])\n",
    "    pbp_txt['predictor'] = {}\n",
    "    pbp_txt['againstTheSpread'] = np.array([])\n",
    "    pbp_txt['pickcenter'] = np.array([])\n",
    "\n",
    "    pbp_txt['timeouts'] = {}\n",
    "    # summary endpoint for pickcenter array\n",
    "    summary_url = \"http://site.api.espn.com/apis/site/v2/sports/basketball/wnba/summary?event={}\".format(self.gameId)\n",
    "    summary_resp = self.download(summary_url)\n",
    "    summary = json.loads(summary_resp)\n",
    "\n",
    "    # ESPN's win probability\n",
    "    wp = \"winprobability\"\n",
    "    if wp in summary.keys():\n",
    "        espnWP = summary[\"winprobability\"]\n",
    "    else:\n",
    "        espnWP = np.array([])\n",
    "\n",
    "    if 'news' in pbp_txt.keys():\n",
    "        del pbp_txt['news']\n",
    "    if 'shop' in pbp_txt.keys():\n",
    "        del pbp_txt['shop']\n",
    "    pbp_txt['gameInfo'] = pbp_txt['header']['competitions'][0]\n",
    "    pbp_txt['season'] = pbp_txt['header']['season']\n",
    "    pbp_txt['playByPlaySource'] = pbp_txt['header']['competitions'][0]['playByPlaySource']\n",
    "\n",
    "    pbp_txt['espnWP'] = espnWP\n",
    "    # Home and Away identification variables\n",
    "    homeTeamId = int(pbp_txt['header']['competitions'][0]['competitors'][0]['team']['id'])\n",
    "    awayTeamId = int(pbp_txt['header']['competitions'][0]['competitors'][1]['team']['id'])\n",
    "    homeTeamMascot = str(pbp_txt['header']['competitions'][0]['competitors'][0]['team']['name'])\n",
    "    awayTeamMascot = str(pbp_txt['header']['competitions'][0]['competitors'][1]['team']['name'])\n",
    "    homeTeamName = str(pbp_txt['header']['competitions'][0]['competitors'][0]['team']['location'])\n",
    "    awayTeamName = str(pbp_txt['header']['competitions'][0]['competitors'][1]['team']['location'])\n",
    "    homeTeamAbbrev = str(pbp_txt['header']['competitions'][0]['competitors'][0]['team']['abbreviation'])\n",
    "    awayTeamAbbrev = str(pbp_txt['header']['competitions'][0]['competitors'][1]['team']['abbreviation'])\n",
    "    homeTeamNameAlt = re.sub(\"Stat(.+)\", \"St\", str(homeTeamName))\n",
    "    awayTeamNameAlt = re.sub(\"Stat(.+)\", \"St\", str(awayTeamName))\n",
    "\n",
    "    if len(pbp_txt['pickcenter']) > 1:\n",
    "        if 'spread' in pbp_txt['pickcenter'][1].keys():\n",
    "            gameSpread =  pbp_txt['pickcenter'][1]['spread']\n",
    "            homeFavorite = pbp_txt['pickcenter'][1]['homeTeamOdds']['favorite']\n",
    "            gameSpreadAvailable = True\n",
    "        else:\n",
    "            gameSpread =  pbp_txt['pickcenter'][0]['spread']\n",
    "            homeFavorite = pbp_txt['pickcenter'][0]['homeTeamOdds']['favorite']\n",
    "            gameSpreadAvailable = True\n",
    "\n",
    "    else:\n",
    "        gameSpread = 2.5\n",
    "        homeFavorite = True\n",
    "        gameSpreadAvailable = False\n",
    "\n",
    "    if (pbp_txt['playByPlaySource'] != \"none\") & (len(pbp_txt['plays'])>1):\n",
    "        pbp_txt['plays_mod'] = []\n",
    "        for play in pbp_txt['plays']:\n",
    "            p = self.flatten_json_iterative(play)\n",
    "            pbp_txt['plays_mod'].append(p)\n",
    "        pbp_txt['plays'] = pd.json_normalize(pbp_txt,'plays_mod')\n",
    "        pbp_txt['plays']['season'] = pbp_txt['season']['year']\n",
    "        pbp_txt['plays']['seasonType'] = pbp_txt['season']['type']\n",
    "        pbp_txt['plays'][\"awayTeamId\"] = awayTeamId\n",
    "        pbp_txt['plays'][\"awayTeamName\"] = str(awayTeamName)\n",
    "        pbp_txt['plays'][\"awayTeamMascot\"] = str(awayTeamMascot)\n",
    "        pbp_txt['plays'][\"awayTeamAbbrev\"] = str(awayTeamAbbrev)\n",
    "        pbp_txt['plays'][\"awayTeamNameAlt\"] = str(awayTeamNameAlt)\n",
    "        pbp_txt['plays'][\"homeTeamId\"] = homeTeamId\n",
    "        pbp_txt['plays'][\"homeTeamName\"] = str(homeTeamName)\n",
    "        pbp_txt['plays'][\"homeTeamMascot\"] = str(homeTeamMascot)\n",
    "        pbp_txt['plays'][\"homeTeamAbbrev\"] = str(homeTeamAbbrev)\n",
    "        pbp_txt['plays'][\"homeTeamNameAlt\"] = str(homeTeamNameAlt)\n",
    "        # Spread definition\n",
    "        pbp_txt['plays'][\"homeTeamSpread\"] = 2.5\n",
    "        pbp_txt['plays'][\"gameSpread\"] = abs(gameSpread)\n",
    "        pbp_txt['plays'][\"homeTeamSpread\"] = np.where(homeFavorite == True, abs(gameSpread), -1*abs(gameSpread))\n",
    "        pbp_txt['homeTeamSpread'] = np.where(homeFavorite == True, abs(gameSpread), -1*abs(gameSpread))\n",
    "        pbp_txt['plays'][\"homeFavorite\"] = homeFavorite\n",
    "        pbp_txt['plays'][\"gameSpread\"] = gameSpread\n",
    "        pbp_txt['plays'][\"gameSpreadAvailable\"] = gameSpreadAvailable\n",
    "        pbp_txt['plays'] = pbp_txt['plays'].to_dict(orient='records')\n",
    "        pbp_txt['plays'] = pd.DataFrame(pbp_txt['plays'])\n",
    "        pbp_txt['plays']['season'] = pbp_txt['header']['season']['year']\n",
    "        pbp_txt['plays']['seasonType'] = pbp_txt['header']['season']['type']\n",
    "        pbp_txt['plays']['game_id'] = int(self.gameId)\n",
    "        pbp_txt['plays'][\"homeTeamId\"] = homeTeamId\n",
    "        pbp_txt['plays'][\"awayTeamId\"] = awayTeamId\n",
    "        pbp_txt['plays'][\"homeTeamName\"] = str(homeTeamName)\n",
    "        pbp_txt['plays'][\"awayTeamName\"] = str(awayTeamName)\n",
    "        pbp_txt['plays'][\"homeTeamMascot\"] = str(homeTeamMascot)\n",
    "        pbp_txt['plays'][\"awayTeamMascot\"] = str(awayTeamMascot)\n",
    "        pbp_txt['plays'][\"homeTeamAbbrev\"] = str(homeTeamAbbrev)\n",
    "        pbp_txt['plays'][\"awayTeamAbbrev\"] = str(awayTeamAbbrev)\n",
    "        pbp_txt['plays'][\"homeTeamNameAlt\"] = str(homeTeamNameAlt)\n",
    "        pbp_txt['plays'][\"awayTeamNameAlt\"] = str(awayTeamNameAlt)\n",
    "        pbp_txt['plays']['period.number'] = pbp_txt['plays']['period.number'].apply(lambda x: int(x))\n",
    "        pbp_txt['plays']['qtr'] = pbp_txt['plays']['period.number'].apply(lambda x: int(x))\n",
    "\n",
    "        #----- Figuring out Timeouts ---------\n",
    "        pbp_txt['timeouts'] = {}\n",
    "        pbp_txt['timeouts'][homeTeamId] = {\"1\": [], \"2\": []}\n",
    "        pbp_txt['timeouts'][awayTeamId] = {\"1\": [], \"2\": []}\n",
    "\n",
    "\n",
    "        pbp_txt['plays'][\"gameSpread\"] = abs(gameSpread)\n",
    "        pbp_txt['plays'][\"gameSpreadAvailable\"] = gameSpreadAvailable\n",
    "        pbp_txt['plays'][\"homeTeamSpread\"] = np.where(homeFavorite == True, abs(gameSpread), -1*abs(gameSpread))\n",
    "        pbp_txt['homeTeamSpread'] = np.where(homeFavorite == True, abs(gameSpread), -1*abs(gameSpread))\n",
    "        pbp_txt['plays'][\"homeFavorite\"] = homeFavorite\n",
    "        pbp_txt['plays'][\"gameSpread\"] = gameSpread\n",
    "        pbp_txt['plays'][\"homeFavorite\"] = homeFavorite\n",
    "\n",
    "        #----- Time ---------------\n",
    "        pbp_txt['plays']['time'] = pbp_txt['plays']['clock.displayValue']\n",
    "        pbp_txt['plays']['clock.mm'] = pbp_txt['plays']['clock.displayValue'].str.split(pat=':')\n",
    "        pbp_txt['plays'][['clock.minutes','clock.seconds']] = pbp_txt['plays']['clock.mm'].to_list()\n",
    "        pbp_txt['plays']['half'] = np.where(pbp_txt['plays']['qtr'] <= 2, \"1\",\"2\")\n",
    "        pbp_txt['plays']['game_half'] = np.where(pbp_txt['plays']['qtr'] <= 2, \"1\",\"2\")\n",
    "        pbp_txt['plays']['lag_qtr'] = pbp_txt['plays']['qtr'].shift(1)\n",
    "        pbp_txt['plays']['lead_qtr'] = pbp_txt['plays']['qtr'].shift(-1)\n",
    "        pbp_txt['plays']['lag_game_half'] = pbp_txt['plays']['game_half'].shift(1)\n",
    "        pbp_txt['plays']['lead_game_half'] = pbp_txt['plays']['game_half'].shift(-1)\n",
    "        pbp_txt['plays']['start.quarter_seconds_remaining'] = 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int)\n",
    "        pbp_txt['plays']['start.half_seconds_remaining'] = np.where(\n",
    "            pbp_txt['plays']['qtr'].isin([1,3]),\n",
    "            600 + 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int),\n",
    "            60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int)\n",
    "        )\n",
    "        pbp_txt['plays']['start.game_seconds_remaining'] = np.select(\n",
    "            [\n",
    "                pbp_txt['plays']['qtr'] == 1,\n",
    "                pbp_txt['plays']['qtr'] == 2,\n",
    "                pbp_txt['plays']['qtr'] == 3,\n",
    "                pbp_txt['plays']['qtr'] == 4\n",
    "            ],\n",
    "            [\n",
    "                1800 + 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int),\n",
    "                1200 + 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int),\n",
    "                600 + 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int),\n",
    "                60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int)\n",
    "            ], default = 60*pbp_txt['plays']['clock.minutes'].astype(int) + pbp_txt['plays']['clock.seconds'].astype(int)\n",
    "        )\n",
    "        # Pos Team - Start and End Id\n",
    "        pbp_txt['plays']['game_play_number'] = np.arange(len(pbp_txt['plays']))+1\n",
    "        pbp_txt['plays']['text'] = pbp_txt['plays']['text'].astype(str)\n",
    "        pbp_txt['plays']['id'] = pbp_txt['plays']['id'].apply(lambda x: int(x))\n",
    "        pbp_txt['plays']['end.quarter_seconds_remaining'] = pbp_txt['plays']['start.quarter_seconds_remaining'].shift(1)\n",
    "        pbp_txt['plays']['end.half_seconds_remaining'] = pbp_txt['plays']['start.half_seconds_remaining'].shift(1)\n",
    "        pbp_txt['plays']['end.game_seconds_remaining'] = pbp_txt['plays']['start.game_seconds_remaining'].shift(1)\n",
    "        pbp_txt['plays']['end.quarter_seconds_remaining'] = np.select(\n",
    "            [\n",
    "                (pbp_txt['plays']['game_play_number'] == 1)|\n",
    "                ((pbp_txt['plays']['qtr'] == 2) & (pbp_txt['plays']['lag_qtr'] == 1))|\n",
    "                ((pbp_txt['plays']['qtr'] == 3) & (pbp_txt['plays']['lag_qtr'] == 2))|\n",
    "                ((pbp_txt['plays']['qtr'] == 4) & (pbp_txt['plays']['lag_qtr'] == 3))\n",
    "            ],\n",
    "            [\n",
    "                600\n",
    "            ], default = pbp_txt['plays']['end.quarter_seconds_remaining']\n",
    "        )\n",
    "        pbp_txt['plays']['end.half_seconds_remaining'] = np.select(\n",
    "            [\n",
    "                (pbp_txt['plays']['game_play_number'] == 1)|\n",
    "                ((pbp_txt['plays']['game_half'] == \"2\") & (pbp_txt['plays']['lag_game_half'] == \"1\"))\n",
    "            ],\n",
    "            [\n",
    "                1200\n",
    "            ], default = pbp_txt['plays']['end.half_seconds_remaining']\n",
    "        )\n",
    "        pbp_txt['plays']['end.game_seconds_remaining'] = np.select(\n",
    "            [\n",
    "                (pbp_txt['plays']['game_play_number'] == 1),\n",
    "                ((pbp_txt['plays']['game_half'] == \"2\") & (pbp_txt['plays']['lag_game_half'] == \"1\"))\n",
    "            ],\n",
    "            [\n",
    "                2400,\n",
    "                1200\n",
    "            ], default = pbp_txt['plays']['end.game_seconds_remaining']\n",
    "        )\n",
    "\n",
    "        pbp_txt['plays']['period'] = pbp_txt['plays']['qtr']\n",
    "\n",
    "        del pbp_txt['plays']['clock.mm']\n",
    "    else:\n",
    "        pbp_txt['plays'] = pd.DataFrame()\n",
    "        pbp_txt['timeouts'] = {}\n",
    "        pbp_txt['timeouts'][homeTeamId] = {\"1\": [], \"2\": []}\n",
    "        pbp_txt['timeouts'][awayTeamId] = {\"1\": [], \"2\": []}\n",
    "    if 'winprobability' not in pbp_txt.keys():\n",
    "        pbp_txt['winprobability'] = np.array([])\n",
    "    if 'standings' not in pbp_txt.keys():\n",
    "        pbp_txt['standings'] = np.array([])\n",
    "    if 'videos' not in pbp_txt.keys():\n",
    "        pbp_txt['videos'] = np.array([])\n",
    "    if 'broadcasts' not in pbp_txt.keys():\n",
    "        pbp_txt['broadcasts'] = np.array([])\n",
    "    pbp_txt['plays'] = pbp_txt['plays'].replace({np.nan: None})\n",
    "    self.plays_json = pbp_txt['plays']\n",
    "    pbp_json = {\n",
    "        \"gameId\": self.gameId,\n",
    "        \"plays\" : pbp_txt['plays'].to_dict(orient='records'),\n",
    "        \"winprobability\" : np.array(pbp_txt['winprobability']).tolist(),\n",
    "        \"boxscore\" : pbp_txt['boxscore'],\n",
    "        \"header\" : pbp_txt['header'],\n",
    "        # \"homeTeamSpread\" : np.array(pbp_txt['homeTeamSpread']).tolist(),\n",
    "        \"broadcasts\" : np.array(pbp_txt['broadcasts']).tolist(),\n",
    "        \"videos\" : np.array(pbp_txt['videos']).tolist(),\n",
    "        \"playByPlaySource\": pbp_txt['playByPlaySource'],\n",
    "        \"standings\" : pbp_txt['standings'],\n",
    "        \"timeouts\" : pbp_txt['timeouts'],\n",
    "        \"pickcenter\" : np.array(pbp_txt['pickcenter']).tolist(),\n",
    "        \"espnWP\" : np.array(pbp_txt['espnWP']).tolist(),\n",
    "        \"gameInfo\" : np.array(pbp_txt['gameInfo']).tolist(),\n",
    "        \"season\" : np.array(pbp_txt['season']).tolist()\n",
    "    }\n",
    "    return pbp_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}